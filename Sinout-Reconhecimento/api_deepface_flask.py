# -*- coding: utf-8 -*-

# ============================================================
# ü§ñ API PYTHON DEEPFACE - O DETETIVE DE EMO√á√ïES
# ============================================================
# Analogia RPG: Este √© o "Mago Especialista em Leitura Mental"!
# Ele consegue olhar para uma foto e dizer:
# - Que emo√ß√£o a pessoa est√° sentindo (feliz, triste, bravo...)
# - Quantos anos tem (aproximado)
# - Se √© homem ou mulher
# - E onde est√° o rosto na foto
#
# Analogia M√©dica: √â o "Especialista em Express√µes Faciais"!
# Como um m√©dico que consegue diagnosticar o estado emocional
# s√≥ de olhar o rosto do paciente.
#
# Como funciona:
# 1. Recebe uma foto (do navegador/c√¢mera)
# 2. Usa Intelig√™ncia Artificial (DeepFace) para analisar
# 3. Retorna as emo√ß√µes detectadas com percentuais
#
# IMPORTANTE: Esta API roda localmente (localhost) por seguran√ßa!
# ============================================================

from flask import Flask, request, jsonify
from flask_cors import CORS
from deepface import DeepFace  # üß† A "Intelig√™ncia Artificial" que detecta emo√ß√µes
import cv2  # üì∏ Biblioteca para processar imagens
import numpy as np  # üî¢ Matem√°tica para trabalhar com imagens
import base64  # üîê Para converter imagens em texto (base64)
from datetime import datetime
from functools import wraps

import traceback  # üêõ Para mostrar erros detalhados


app = Flask(__name__)
CORS(app)  # ‚úÖ Permite que o frontend (C#/JavaScript) chame esta API

# ‚öôÔ∏è CONFIGURA√á√ïES
MODELO_PADRAO = "Facenet"  # Modelo de IA: r√°pido e preciso
API_KEY_SECRETA = "PYTHON_API_SECRET_KEY_2024_SINOUT_DEEPFACE_SECURE_ACCESS"  # üîë Senha secreta (mesma do C#)

# ============================================================
# üõ°Ô∏è MIDDLEWARE DE SEGURAN√áA - O GUARDA DO PORT√ÉO
# ============================================================
# Analogia RPG: √â como o "Guarda da Torre" que verifica crach√°s!
# Antes de processar qualquer pedido, verifica se tem a senha correta.
#
# Funcionamento:
# 1. Cliente (C# ou outro) envia header: X-API-Key: SENHA_SECRETA
# 2. Este decorator verifica se a senha est√° correta
# 3. Se sim, permite entrar. Se n√£o, bloqueia!
#
# √â como um nightclub que s√≥ deixa entrar quem tem convite!
# ============================================================
def require_api_key(f):
    """Decorator que valida X-API-Key header antes de processar requisi√ß√£o"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # üîç FASE 1: Procurar a chave na requisi√ß√£o
        api_key = request.headers.get('X-API-Key')
        
        # ‚ùå VALIDA√á√ÉO 1: Esqueceu de enviar a chave?
        if not api_key:
            return jsonify({
                "sucesso": False,
                "erro": "API Key n√£o fornecida",
                "mensagem": "Envie o header X-API-Key na requisi√ß√£o"
            }), 401  # 401 = N√£o autenticado
        
        # ‚ùå VALIDA√á√ÉO 2: Chave errada?
        if api_key != API_KEY_SECRETA:
            return jsonify({
                "sucesso": False,
                "erro": "API Key inv√°lida",
                "mensagem": "A chave de API fornecida n√£o √© v√°lida"
            }), 403  # 403 = Proibido
        
        # ‚úÖ Chave correta! Pode entrar!
        return f(*args, **kwargs)
    
    return decorated_function

# ============================================================
# üè† ROTA INICIAL - A PORTA DA FRENTE
# ============================================================
# Analogia: √â como a recep√ß√£o de um pr√©dio!
# Mostra informa√ß√µes b√°sicas sobre o servi√ßo.
# URL: GET http://localhost:5000/
# ============================================================
@app.route('/')
def home():
    """Rota inicial - verifica se API est√° rodando"""
    return jsonify({
        "status": "online",
        "mensagem": "API DeepFace Flask funcionando!",
        "versao": "2.0",
        "seguranca": "Protegido por API Key (X-API-Key header)",
        "endpoints": [
            "POST /analyze - Analisa uma imagem (REQUER X-API-Key)",
            "POST /analyze-base64 - Analisa imagem em base64 (REQUER X-API-Key)",
            "GET /models - Lista modelos dispon√≠veis (REQUER X-API-Key)",
            "GET /health - Verifica sa√∫de da API (REQUER X-API-Key)"
        ]
    })

# ============================================================
# üíì HEALTH CHECK - VERIFICA√á√ÉO DE SA√öDE
# ============================================================
# Analogia RPG: Como verificar se o NPC ainda est√° vivo!
# Endpoint simples para checar se o servi√ßo est√° funcionando.
# ============================================================
@app.route('/health')
@require_api_key  # üîê Requer senha
def health():
    """Endpoint para health check"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    })

# ============================================================
# üìö LISTAR MODELOS - O CAT√ÅLOGO DE MAGOS
# ============================================================
# Analogia RPG: Ver lista de "Classes de Mago" dispon√≠veis!
# Cada modelo de IA tem vantagens/desvantagens:
# - Facenet: R√°pido e preciso (RECOMENDADO)
# - VGG-Face: Muito preciso mas lento
# - OpenFace: Super r√°pido mas menos preciso
# ============================================================
@app.route('/models', methods=['GET'])
@require_api_key  # üîê Requer senha
def listar_modelos():
    """Lista os modelos dispon√≠veis"""
    return jsonify({
        "modelos_disponiveis": [
            {"nome": "Facenet", "precisao": "97.4%", "velocidade": "r√°pido", "recomendado": True},
            {"nome": "VGG-Face", "precisao": "97.78%", "velocidade": "m√©dio", "recomendado": False},
            {"nome": "Facenet512", "precisao": "98.4%", "velocidade": "lento", "recomendado": False},
            {"nome": "OpenFace", "precisao": "78.7%", "velocidade": "muito r√°pido", "recomendado": False},
            {"nome": "ArcFace", "precisao": "96.7%", "velocidade": "m√©dio", "recomendado": False},
            {"nome": "Dlib", "precisao": "96.8%", "velocidade": "m√©dio", "recomendado": False}
        ],
        "modelo_padrao": MODELO_PADRAO
    })

# ============================================================
# üîÆ AN√ÅLISE DE EMO√á√ïES - O CORA√á√ÉO DA API!
# ============================================================
# Analogia RPG: A "Magia Principal" do Mago!
# Esta √© a fun√ß√£o mais importante - detecta emo√ß√µes em uma foto.
#
# Analogia M√©dica: O "Exame Principal"!
# O paciente (foto) entra, o m√©dico (IA) examina e d√° o diagn√≥stico (emo√ß√µes).
#
# Como usar:
# 1. Frontend tira foto da c√¢mera
# 2. Envia arquivo de imagem via POST
# 3. Esta rota processa com DeepFace
# 4. Retorna: emo√ß√£o dominante, todas as emo√ß√µes com %, idade, g√™nero
#
# Par√¢metros:
# - file: arquivo de imagem (OBRIGAT√ìRIO)
# - model: qual modelo de IA usar (opcional, padr√£o: Facenet)
# - actions: o que analisar (opcional, padr√£o: emo√ß√£o, idade, g√™nero)
#
# Exemplo de retorno:
# {
#   "sucesso": true,
#   "analise": {
#     "emocao_dominante": "happy",
#     "emocoes": {
#       "happy": 85.5,
#       "neutral": 10.2,
#       "sad": 2.1,
#       "angry": 1.0,
#       "fear": 0.8,
#       "disgust": 0.3,
#       "surprise": 0.1
#     },
#     "idade": 28,
#     "genero": "Man"
#   }
# }
# ============================================================
@app.route('/analyze', methods=['POST'])
@require_api_key  # üîê Requer senha
def analisar_imagem():
    """
    Analisa uma imagem enviada via multipart/form-data

    Par√¢metros:
        - file: arquivo de imagem (obrigat√≥rio)
        - detector: detector de faces (opcional, padr√£o: opencv)
        - actions: lista de an√°lises (opcional, padr√£o: emotion,age,gender)

    Retorna:
        JSON com an√°lise da face
    """
    try:
        # ‚ùå VALIDA√á√ÉO 1: Arquivo enviado?
        if 'file' not in request.files:
            return jsonify({
                "sucesso": False,
                "erro": "Nenhum arquivo enviado. Use o campo 'file'"
            }), 400

        file = request.files['file']

        # ‚ùå VALIDA√á√ÉO 2: Nome do arquivo vazio?
        if file.filename == '':
            return jsonify({
                "sucesso": False,
                "erro": "Nome do arquivo vazio"
            }), 400

        # ‚öôÔ∏è FASE 1: LER PAR√ÇMETROS OPCIONAIS
        # Nota: 'model' √© ignorado pois analyze() usa modelos fixos para atributos.
        # Usamos 'detector' para o backend de detec√ß√£o facial.
        detector = request.form.get('detector', 'opencv')
        actions_str = request.form.get('actions', 'emotion,age,gender')
        actions = [a.strip() for a in actions_str.split(',')]

        # üì∏ FASE 2: CONVERTER ARQUIVO EM IMAGEM
        # Analogia: Como revelar uma foto anal√≥gica!
        file_bytes = np.frombuffer(file.read(), np.uint8)  # Ler bytes
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)   # Decodificar imagem

        # ‚ùå VALIDA√á√ÉO 3: Imagem v√°lida?
        if img is None:
            return jsonify({
                "sucesso": False,
                "erro": "N√£o foi poss√≠vel decodificar a imagem"
            }), 400

        # üß† FASE 3: MAGIA! Analisar com DeepFace
        # Analogia: O mago lan√ßando o feiti√ßo de "Leitura Mental"!
        resultado = DeepFace.analyze(
            img,
            actions=actions,              # O que analisar: emo√ß√£o, idade, g√™nero
            enforce_detection=False,      # N√£o falhar se n√£o detectar rosto perfeitamente
            detector_backend=detector,    # Detector de rostos (opencv √© padr√£o e r√°pido)
            silent=True                   # N√£o mostrar logs no console
        )

        # üìä FASE 4: PROCESSAR RESULTADO
        # DeepFace retorna lista se detectar m√∫ltiplas faces, pegamos a primeira
        if isinstance(resultado, list):
            resultado = resultado[0]

        # üéÅ FASE 5: PREPARAR RESPOSTA BONITA
        # Organizar os dados de forma clara para o frontend
        resposta = {
            "sucesso": True,
            "timestamp": datetime.now().isoformat(),  # Quando foi analisado
            "detector_usado": detector,
            "analise": {
                "emocao_dominante": resultado.get('dominant_emotion'),  # Ex: "happy"
                "emocoes": resultado.get('emotion', {}),                 # Ex: {"happy": 85.5, "sad": 10.2, ...}
                "idade": resultado.get('age'),                           # Ex: 28
                "genero": resultado.get('dominant_gender') or resultado.get('gender'),  # Ex: "Man" ou "Woman"
                "raca_dominante": resultado.get('dominant_race'),        # Ex: "white", "asian", etc
                "regiao_face": resultado.get('region', {})               # Coordenadas do rosto na imagem
            },
            "dados_completos": resultado  # Dados brutos completos (para debug)
        }

        return jsonify(resposta), 200  # ‚úÖ Sucesso!

    except Exception as e:
        # üí• TRATAMENTO DE ERRO: Algo deu errado!
        return jsonify({
            "sucesso": False,
            "erro": str(e),
            "tipo_erro": type(e).__name__,
            "traceback": traceback.format_exc()  # Rastreamento completo do erro
        }), 500

@app.route('/analyze-base64', methods=['POST'])
@require_api_key
def analisar_base64():
    """
    Analisa uma imagem enviada em base64

    JSON esperado:
    {
        "image_base64": "...",
        "model": "Facenet" (opcional),
        "actions": ["emotion", "age", "gender"] (opcional)
    }
    """
    try:
        data = request.get_json()

        if not data or 'image_base64' not in data:
            return jsonify({
                "sucesso": False,
                "erro": "Campo 'image_base64' √© obrigat√≥rio no JSON"
            }), 400

        # Decodificar base64
        image_base64 = data['image_base64']

        # Remover prefixo se existir (data:image/png;base64,)
        if ',' in image_base64:
            image_base64 = image_base64.split(',')[1]

        img_data = base64.b64decode(image_base64)
        nparr = np.frombuffer(img_data, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if img is None:
            return jsonify({
                "sucesso": False,
                "erro": "N√£o foi poss√≠vel decodificar a imagem base64"
            }), 400

        # Ler par√¢metros opcionais
        detector = data.get('detector', 'opencv')
        actions = data.get('actions', ['emotion', 'age', 'gender'])

        # Analisar com DeepFace
        # Nota: detector_backend usa opencv, ssd, dlib, mtcnn, etc (n√£o Facenet)
        resultado = DeepFace.analyze(
            img,
            actions=actions,
            enforce_detection=False,
            detector_backend=detector,  # Usar detector padr√£o
            silent=True
        )

        if isinstance(resultado, list):
            resultado = resultado[0]

        # Preparar resposta estruturada
        resposta = {
            "sucesso": True,
            "timestamp": datetime.now().isoformat(),
            "detector_usado": detector,
            "analise": {
                "emocao_dominante": resultado.get('dominant_emotion'),
                "emocoes": resultado.get('emotion', {}),
                "idade": resultado.get('age'),
                "genero": resultado.get('dominant_gender') or resultado.get('gender'),
                "raca_dominante": resultado.get('dominant_race'),
                "regiao_face": resultado.get('region', {})
            },
            "dados_completos": resultado
        }

        return jsonify(resposta), 200

    except Exception as e:
        return jsonify({
            "sucesso": False,
            "erro": str(e),
            "tipo_erro": type(e).__name__,
            "traceback": traceback.format_exc()
        }), 500

@app.route('/analyze-multiple', methods=['POST'])
def analisar_multiplas():
    """
    Analisa m√∫ltiplas faces em uma imagem
    Detecta todas as faces e retorna an√°lise de cada uma
    """
    try:
        if 'file' not in request.files:
            return jsonify({
                "sucesso": False,
                "erro": "Nenhum arquivo enviado"
            }), 400

        file = request.files['file']
        detector = request.form.get('detector', 'opencv')

        # Ler imagem
        file_bytes = np.frombuffer(file.read(), np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

        if img is None:
            return jsonify({
                "sucesso": False,
                "erro": "Imagem inv√°lida"
            }), 400

        # Detectar faces
        face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))

        resultados = []

        for i, (x, y, w, h) in enumerate(faces):
            face_region = img[y:y+h, x:x+w]

            # Analisar cada face
            resultado = DeepFace.analyze(
                face_region,
                actions=['emotion', 'age', 'gender'],
                enforce_detection=False,
                detector_backend=detector,
                silent=True
            )

            if isinstance(resultado, list):
                resultado = resultado[0]

            resultados.append({
                "face_id": i,
                "coordenadas": {"x": int(x), "y": int(y), "w": int(w), "h": int(h)},
                "emocao_dominante": resultado.get('dominant_emotion'),
                "emocoes": resultado.get('emotion', {}),
                "idade": resultado.get('age'),
                "genero": resultado.get('dominant_gender') or resultado.get('gender')
            })

        return jsonify({
            "sucesso": True,
            "timestamp": datetime.now().isoformat(),
            "detector_usado": detector,
            "total_faces": len(resultados),
            "faces": resultados
        }), 200

    except Exception as e:
        return jsonify({
            "sucesso": False,
            "erro": str(e),
            "traceback": traceback.format_exc()
        }), 500

@app.errorhandler(404)
def nao_encontrado(e):
    return jsonify({
        "sucesso": False,
        "erro": "Endpoint n√£o encontrado",
        "endpoints_disponiveis": ["/", "/analyze", "/analyze-base64", "/analyze-multiple", "/models", "/health"]
    }), 404

@app.errorhandler(500)
def erro_interno(e):
    return jsonify({
        "sucesso": False,
        "erro": "Erro interno do servidor",
        "detalhes": str(e)
    }), 500

if __name__ == '__main__':
    print("="*60)
    print("üöÄ API DeepFace Flask - Modo Interno")
    print("="*60)
    print("‚úÖ Servidor iniciando...")
    print("üìç URL: http://localhost:5000")
    print("üìö Endpoints dispon√≠veis:")
    print("   GET  /           - Informa√ß√µes da API")
    print("   GET  /health     - Health check")
    print("   GET  /models     - Lista modelos")
    print("   POST /analyze    - Analisa imagem (multipart)")
    print("   POST /analyze-base64 - Analisa imagem (base64)")
    print("   POST /analyze-multiple - M√∫ltiplas faces")
    print("="*60)
    print("\n‚ö†Ô∏è  Esta API deve rodar APENAS internamente!")
    print("   Para produ√ß√£o, use: flask run --host=127.0.0.1")
    print("\n")

    # Rodar apenas em localhost (interno)
    app.run(host='127.0.0.1', port=5000, debug=True)
